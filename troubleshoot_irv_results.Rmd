# Set-up

First, load all dependencies.

```{r, message = FALSE, warning = FALSE}
# Load dependencies
library(tidyverse)
library(here)
source(here("code/full_header.R"))  # fn's and data
source(here("code/prep_cses.R"))    # data prep
source(here("code/utils/ternary_functions.R"))    # ternary w/o ggtern
```

Next, load the output from the server script run for the baseline case ($s = 85; \lambda = 0.05$):

```{r}
# Load summary stats
load("output/files/1/85summary_1_85.Rdata")
# Load v_vecs:
load("output/files/1/85v_vecs_1_85.Rdata")
```

# Sweden Analysis

First, let's plot the prevalence of the Sweden case. This is the one very wonky case even after fixing everything else in the code base. 

```{r}
sum_swe = summary_stats %>% 
  filter(System == "IRV" & case == "SWE_2014") %>% 
  mutate(iter = 1:250)

ggplot(sum_swe,
  aes(x = iter, y = Prevalence)) +
  geom_path(aes(group = case, colour = iter), alpha = 0.5)
```

Looks like some big, but very regular oscillation. The v_vec path taken by this case is also rather strange, seemingly moving back and forth. However, it also appears to be far enough from the ternary edge so that the MC simulation doesn't kick in.

```{r, message = FALSE, warnings = FALSE}
v_vec_swe = out$SWE_2014[[1]] %>%
  as.data.frame %>%
  mutate(iter = 1:251, type = "new")

v_vec_df_tern = v_vec_swe %>%
    mutate(A = V1 + V2,
           B = V3 + V4,
           C = V5 + V6,
           C = C + .5 *B,
           B = sqrt(3/4)*B)

ggplot(v_vec_df_tern, aes(x = C, y = B)) +
  geom_path(alpha = 0.3) +
  geom_ternary_boundary() +
  theme_classic()
```

Let's zoom in and mark the path by position in the iteration. (For the reference, the orientation is still the same but the ternary boundaries are no longer displayed)

```{r}
# Zooming in:
ggplot(v_vec_df_tern, aes(x = C, y = B)) +
  geom_point(aes(colour = iter), alpha = 0.7) +
  geom_path(alpha = 0.3) +
  scale_colour_gradient(low = "red", high = "blue") +
  theme_classic()
```

# Digging deeper

Is the above another script bug? OK, let's run the SWE case from the server script to look at it more carefully.

```{r, cache = TRUE}
results = many_iterations_until_convergence(
                        big_list_na_omit[[32]], 
                        big_list_na_omit[[32]]$v_vec, 
                        0.05, 
                        85, 
                        0.001, 
                        250, ae = TRUE)
```

Display the first few observations from 180th and 181th iteration (where one of the jumps up to very high prevalence occurs)

### Small prevalence in 180th iter
```{r}
# Small prevalence (180th)
with(results$rcv_df %>% filter(iter == 180), mean(sin_rcv != opt_rcv))
with(results$rcv_df %>% filter(iter == 180), mean(tau_rcv > 0))
results$rcv_df %>% filter(iter == 180) %>% dplyr::select(sin_rcv, opt_rcv, tau_rcv) %>% head
```

### High prevalence in 181th iter
```{r}
# High prevalence (181th)
with(results$rcv_df %>% filter(iter == 181), mean(sin_rcv != opt_rcv))
with(results$rcv_df %>% filter(iter == 181), mean(tau_rcv > 0))
results$rcv_df %>% filter(iter == 181) %>% dplyr::select(sin_rcv, opt_rcv, tau_rcv) %>% head
```

OK, so it looks like in that iteration quite a few ABC types switch to CBA. 


### Examining utility differences

It also doesn't look like this is an artefact of the floating point error that we'd been dealing with before. Take the second voter (an ABC to CBA type) as an example (which seems pretty typical):

```{r}
with(results$rcv_df %>% filter(iter == 180), CAB[2] - ABC[2])
with(results$rcv_df %>% filter(iter == 181), CAB[2] - ABC[2])
```

### Searching for any 'jumps'

So, is there a threshold or jump at which this occurs? To check, we can take weighted linear combinations between v_vec[180] and v_vec[181] (50 steps between them) and check the resulting best responses.

```{r}
v1 = results$rcv_v_vec[180, ] %>% unlist
v2 = results$rcv_v_vec[181, ] %>% unlist

v1
v2

q = sv(big_list_na_omit[[32]]$U, 
       big_list_na_omit[[32]]$weights, 
   v.vec = v2, 85, "AV")
sum(q$tau > 0) / length(q$tau)


linweights = seq(1, 0, by = -0.02)
lin_combs = map(linweights, ~ .x * v1 + (1 - .x) * v2)

# Apply SV function to all linear combinations between the two v_vecs
tt = map(lin_combs, ~ table(
    sv(big_list_na_omit[[32]]$U, 
       big_list_na_omit[[32]]$weights, 
   v.vec = .x, 85, "AV")$opt.votes.strategic) %>% as.data.frame)

ttdf = tt %>% bind_rows(.id = "lincomb") %>%
  complete(lincomb, Var1, fill = list(Freq = 0)) %>%
  group_by(lincomb) %>%
  mutate(prop = Freq / sum(Freq)) 

ggplot(ttdf, aes(as.numeric(lincomb), prop)) +
  geom_line(aes(colour = Var1, group = Var1)) +
  geom_point(aes(colour = Var1)) +
  labs(x = "Sequence number", y = "Proportion", colour = "Optimal Votes")
```

It does appear like the v_vec is crossing some threshold between the 180th and 181th iteration at which voters start to switch. This further suggests that the calculations may be right and rather than being an anomaly, the observed pattern in the SWE_2014 case is just one very large oscillation.

# Compare to old results

First let's load and reproduce the old results.

```{r}
# Load old code
source("code/archive/archive_utils/av_pivotal_probs_analytical_general_v2.r")
source("code/archive/archive_utils/plurality_pivotal_probabilities_analytical.r")
source("code/utils/sv_old.R")
source("code/utils/many_iterations_old.R")

# Run old results
results_old = many_iterations_until_convergence_old(
                        big_list_na_omit[[32]], 
                        big_list_na_omit[[32]]$v_vec, 
                        0.05, 
                        85, 
                        0.001, 
                        250)

```

## V.vec path

Looks very similar, but is slightly different.

```{r}
v_vec_swe_old = results_old$rcv_v_vec %>%
  as.data.frame %>%
  mutate(iter = 1:251, type = "old")

all_vec = rbind(v_vec_swe, v_vec_swe_old)

all_tern = all_vec %>%
    mutate(A = V1 + V2,
           B = V3 + V4,
           C = V5 + V6,
           C = C + .5 *B,
           B = sqrt(3/4)*B)

ggplot(all_tern, aes(x = C, y = B)) +
  geom_point(aes(colour = type), alpha = 0.7) +
  geom_path(alpha = 0.3, aes(group = type)) +
  # scale_colour_gradient(low = "red", high = "blue") +
  theme_classic()
```

## Prevalence analysis

Let's find out if the two functions yield the same prevalence for the same given v_vec. The old function yields a very similar prevalence for the same v_vec!

```{r}
# Take the v2 that had previously high prevalence
q = sv(big_list_na_omit[[32]]$U, 
       big_list_na_omit[[32]]$weights, 
   v.vec = v2, 85, "AV")
sum(q$tau > 0) / length(q$tau)

q_old = sv_old(big_list_na_omit[[32]]$U, 
       big_list_na_omit[[32]]$weights, 
   v.vec = v2, 85, "AV")
sum(q_old$tau > 0) / length(q_old$tau)
```

```{r}
prev_old_df = results_old$rcv_df %>% group_by(iter) %>%
  summarise(prev = mean(tau_rcv > 0))
plot(prev_old_df$iter, prev_old_df$prev)
```

Meanwhile, both approaches yield (the same) very low prevalence for the 181th iteration in the old sequence.

```{r}
v2_old = results_old$rcv_v_vec[181, ] %>% unlist

q = sv(big_list_na_omit[[32]]$U, 
       big_list_na_omit[[32]]$weights, 
   v.vec = v2_old, 85, "AV")
sum(q$tau > 0) / length(q$tau)

q_old = sv_old(big_list_na_omit[[32]]$U, 
       big_list_na_omit[[32]]$weights, 
   v.vec = v2_old, 85, "AV")
sum(q_old$tau > 0) / length(q_old$tau)
```

We can do the same step-by-step sequence again -- this time by creating linear combinations between `v2` and `v2_old`.

```{r}
lin_combs = map(linweights, ~ .x * v2_old + (1 - .x) * v2)

# Apply SV function to all linear combinations between the two v_vecs
tt = map(lin_combs, ~ table(
    sv(big_list_na_omit[[32]]$U, 
       big_list_na_omit[[32]]$weights, 
   v.vec = .x, 85, "AV")$opt.votes.strategic) %>% as.data.frame)

tt_old = map(lin_combs, ~ table(
    sv_old(big_list_na_omit[[32]]$U, 
       big_list_na_omit[[32]]$weights, 
   v.vec = .x, 85, "AV")$opt.votes.strategic) %>% as.data.frame)

ttdf = tt %>% bind_rows(.id = "lincomb") %>%
  complete(lincomb, Var1, fill = list(Freq = 0)) %>%
  group_by(lincomb) %>%
  mutate(prop = Freq / sum(Freq), method = "new") 

ttdf_old = tt %>% bind_rows(.id = "lincomb") %>%
  complete(lincomb, Var1, fill = list(Freq = 0)) %>%
  group_by(lincomb) %>%
  mutate(prop = Freq / sum(Freq), method = "old") 

comp_df = rbind(ttdf, ttdf_old)

ggplot(comp_df, aes(as.numeric(lincomb), prop)) +
  geom_line(aes(colour = Var1, group = Var1)) +
  geom_point(aes(colour = Var1)) +
  labs(x = "Sequence number", y = "Proportion", colour = "Optimal Votes") +
  facet_wrap(~ method)

```